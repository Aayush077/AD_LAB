{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aayush077/AD_LAB/blob/main/Copy_of_earthquake_predictor_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbe27596",
      "metadata": {
        "id": "bbe27596"
      },
      "source": [
        "# Earthquake Prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Libraries"
      ],
      "metadata": {
        "id": "s7VJtQgzFrYV"
      },
      "id": "s7VJtQgzFrYV"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import data_table\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install cartopy\n",
        "import cartopy.crs as ccrs\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "au2wvkCvFueO"
      },
      "id": "au2wvkCvFueO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing dataset"
      ],
      "metadata": {
        "id": "2re0OzihIZlH"
      },
      "id": "2re0OzihIZlH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "200873ba",
      "metadata": {
        "id": "200873ba"
      },
      "outputs": [],
      "source": [
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "df_raw = pd.read_csv('earthquake_1995-2023.csv')\n",
        "\n",
        "display(df_raw.head())\n",
        "display(df_raw.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_raw.columns)\n"
      ],
      "metadata": {
        "id": "ETocrF1T_JJc"
      },
      "id": "ETocrF1T_JJc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Visualization of data"
      ],
      "metadata": {
        "id": "wcBdFQ76-Wtv"
      },
      "id": "wcBdFQ76-Wtv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmob9X3S-aH3"
      },
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "ax.set_global()\n",
        "\n",
        "ax.coastlines()\n",
        "ax.stock_img()\n",
        "ax.add_feature(__import__(\"cartopy\").feature.BORDERS)\n",
        "\n",
        "plt.scatter(df_raw['longitude'], df_raw['latitude'],s=2, color='red',\n",
        "    transform=ccrs.PlateCarree()\n",
        ")\n",
        "\n",
        "plt.title(\"All Affected Areas (Earthquake Locations)\", fontsize=16)\n",
        "plt.show()\n"
      ],
      "id": "Kmob9X3S-aH3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Correlation HEATMAP\n",
        "# Pick only the numeric columns and find how they relate\n",
        "corr = df_raw.select_dtypes(include='number').corr()\n",
        "\n",
        "# Draw the heatmap\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(corr, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8fov8DrYCWdn"
      },
      "id": "8fov8DrYCWdn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing & Spliting\n"
      ],
      "metadata": {
        "id": "PjVVhUo4IfHw"
      },
      "id": "PjVVhUo4IfHw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Shows information about your dataset, Creates a safe copy to work on"
      ],
      "metadata": {
        "id": "YqPW1Nb0Iuph"
      },
      "id": "YqPW1Nb0Iuph"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aaaa0e3",
      "metadata": {
        "id": "3aaaa0e3"
      },
      "outputs": [],
      "source": [
        "print('Columns:', list(df_raw.columns))\n",
        "print('\\nDtypes:\\n', df_raw.dtypes)\n",
        "print('\\nMissing values per column:\\n', df_raw.isna().sum())\n",
        "\n",
        "df = df_raw.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d42b00d",
      "metadata": {
        "id": "2d42b00d"
      },
      "outputs": [],
      "source": [
        "# clean and standardize column names – only rename what exists in your dataset\n",
        "col_map = {\n",
        "    'mag': 'magnitude',\n",
        "    'magnitude': 'magnitude',\n",
        "    'date_time': 'date_time',\n",
        "    'time': 'time',\n",
        "    'latitude': 'latitude',\n",
        "    'longitude': 'longitude',\n",
        "    'depth': 'depth',\n",
        "    'magType': 'magType',\n",
        "    'nst': 'num_stations',\n",
        "    'dmin': 'dmin',\n",
        "    'gap': 'gap',\n",
        "    'rms': 'rms',\n",
        "    'mmi': 'mmi',\n",
        "    'cdi': 'cdi',\n",
        "    'alert': 'alert',\n",
        "    'tsunami': 'tsunami',\n",
        "    'country': 'country',\n",
        "    'continent': 'continent',\n",
        "    'location': 'location',\n",
        "    'title': 'title',\n",
        "    'sig': 'sig'\n",
        "}\n",
        "\n",
        "# Apply renaming only to matching columns\n",
        "df = df.rename(columns={c: col_map[c] for c in df.columns if c in col_map})\n",
        "\n",
        "print(\"Renamed columns:\")\n",
        "print(df.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c77fc8aa",
      "metadata": {
        "id": "c77fc8aa"
      },
      "outputs": [],
      "source": [
        "# Parse datetime column\n",
        "if 'date_time' in df.columns:\n",
        "    df['date_time'] = pd.to_datetime(df['date_time'], errors='coerce')\n",
        "    print(\"\\nInvalid datetime rows:\", df['date_time'].isna().sum())\n",
        "\n",
        "    df['year'] = df['date_time'].dt.year\n",
        "    df['month'] = df['date_time'].dt.month\n",
        "    df['day'] = df['date_time'].dt.day\n",
        "    df['hour'] = df['date_time'].dt.hour\n",
        "\n",
        "    df = df.set_index('date_time')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88e450c2",
      "metadata": {
        "id": "88e450c2"
      },
      "outputs": [],
      "source": [
        "# Select useful features\n",
        "feature_list = [\n",
        "    'latitude','longitude','depth','num_stations','dmin','gap','rms',\n",
        "    'mmi','cdi','tsunami','sig','year','month','hour',\n",
        "    'magType','alert','continent','country','location','title'\n",
        "]\n",
        "\n",
        "keep_cols = [c for c in feature_list if c in df.columns]\n",
        "print(\"Keeping columns:\", keep_cols)\n",
        "\n",
        "df_model = df[keep_cols + ['magnitude']].copy()\n",
        "\n",
        "df_model = df_model.dropna(subset=['magnitude'])\n",
        "\n",
        "#missing values handling\n",
        "num_cols = df_model.select_dtypes(include=['number']).columns.drop('magnitude')\n",
        "df_model[num_cols] = df_model[num_cols].fillna(df_model[num_cols].median())\n",
        "\n",
        "cat_cols = df_model.select_dtypes(include=['object']).columns\n",
        "df_model[cat_cols] = df_model[cat_cols].fillna('missing')\n",
        "\n",
        "print(\"Missing values after cleaning:\\n\", df_model.isna().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_model['magnitude'].describe())\n",
        "print(\"\\nRounded magnitude counts:\")\n",
        "print(df_model['magnitude'].round().value_counts().sort_index())"
      ],
      "metadata": {
        "id": "tQQYBsIeFISi"
      },
      "id": "tQQYBsIeFISi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CORE PREPROCESSING AND SPLITING OF DATASET"
      ],
      "metadata": {
        "id": "SIsGZlHgKuTU"
      },
      "id": "SIsGZlHgKuTU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0f67ad5",
      "metadata": {
        "id": "a0f67ad5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import joblib\n",
        "\n",
        "# Create a 'mag_class' column by rounding the 'magnitude' for classification\n",
        "df_model['mag_class'] = df_model['magnitude'].round().astype(int)\n",
        "\n",
        "# Remap 'mag_class' to be 0-indexed for XGBoost\n",
        "# Get unique sorted classes to create a mapping\n",
        "unique_classes = sorted(df_model['mag_class'].unique())\n",
        "class_mapping = {old_val: new_val for new_val, old_val in enumerate(unique_classes)}\n",
        "df_model['mag_class'] = df_model['mag_class'].map(class_mapping)\n",
        "\n",
        "# Train-test split (CLASSIFICATION)\n",
        "X = df_model.drop(columns=['magnitude', 'mag_class'])\n",
        "y = df_model['mag_class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train/Test shapes:\", X_train.shape, X_test.shape)\n",
        "\n",
        "# Identify numeric and categorical features\n",
        "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(\"Numeric:\", numeric_features)\n",
        "print(\"Categorical:\", categorical_features)\n",
        "\n",
        "# Transformers\n",
        "numeric_transformer = StandardScaler()\n",
        "categorical_transformer = OneHotEncoder(\n",
        "    handle_unknown='ignore',\n",
        "    sparse_output=False\n",
        ")\n",
        "\n",
        "# Build preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"cat\", categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "aSTTwwUbvC9k"
      },
      "id": "aSTTwwUbvC9k"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Logistic Regression Pipeline\n",
        "lr_model = Pipeline(steps=[\n",
        "    ('pre', preprocessor),\n",
        "    ('model', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# Train\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_lr)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lr))\n"
      ],
      "metadata": {
        "id": "97TGEGDVvI-j"
      },
      "id": "97TGEGDVvI-j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Visualization(Actual Vs Predicted Logistic Reg)"
      ],
      "metadata": {
        "id": "kYetwQbRv6Gu"
      },
      "id": "kYetwQbRv6Gu"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test,\n",
        "    y_pred_lr,\n",
        "    cmap='Blues',\n",
        "    xticks_rotation=45\n",
        ")\n",
        "\n",
        "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rWHY5bwOv5jg"
      },
      "id": "rWHY5bwOv5jg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##KNN CLASSIFIER"
      ],
      "metadata": {
        "id": "NqqQu7PcZ7O2"
      },
      "id": "NqqQu7PcZ7O2"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# KNN Classifier Pipeline\n",
        "knn_model = Pipeline(steps=[\n",
        "    ('pre', preprocessor),\n",
        "    ('model', KNeighborsClassifier(n_neighbors=5))\n",
        "])\n",
        "\n",
        "# Train\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_knn = knn_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "\n",
        "print(\"KNN Accuracy:\", accuracy_knn)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_knn))\n"
      ],
      "metadata": {
        "id": "cfN8zCO4Z94A"
      },
      "id": "cfN8zCO4Z94A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Visulaization KNN"
      ],
      "metadata": {
        "id": "6k9LaPBjaG-X"
      },
      "id": "6k9LaPBjaG-X"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test,\n",
        "    y_pred_knn,\n",
        "    cmap='Blues',\n",
        "    xticks_rotation=45\n",
        ")\n",
        "\n",
        "plt.title(\"Confusion Matrix - KNN Classifier\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DpUJYpdtaGfb"
      },
      "id": "DpUJYpdtaGfb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##NAIVE BAYES CLASSIFIER"
      ],
      "metadata": {
        "id": "AqD5Lhrzay7C"
      },
      "id": "AqD5Lhrzay7C"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Naive Bayes Pipeline\n",
        "nb_model = Pipeline(steps=[\n",
        "    ('pre', preprocessor),\n",
        "    ('model', GaussianNB())\n",
        "])\n",
        "\n",
        "# Train\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "\n",
        "print(\"Naive Bayes Accuracy:\", accuracy_nb)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_nb))\n"
      ],
      "metadata": {
        "id": "535FwdxXa56N"
      },
      "id": "535FwdxXa56N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###VISUALIZATION NAIVE BAYES CLA"
      ],
      "metadata": {
        "id": "yOz3O9fibASj"
      },
      "id": "yOz3O9fibASj"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test,\n",
        "    y_pred_nb,\n",
        "    cmap='Blues',\n",
        "    xticks_rotation=45\n",
        ")\n",
        "\n",
        "plt.title(\"Confusion Matrix - Naive Bayes\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "voRlwwKca-12"
      },
      "id": "voRlwwKca-12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ADABOOST CLASSIFIER"
      ],
      "metadata": {
        "id": "DwuGDwz9h2Gk"
      },
      "id": "DwuGDwz9h2Gk"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# AdaBoost Classifier Pipeline\n",
        "ada_model = Pipeline(steps=[\n",
        "    ('pre', preprocessor),\n",
        "    ('model', AdaBoostClassifier(\n",
        "        n_estimators=200,\n",
        "        learning_rate=0.5,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train\n",
        "ada_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_ada = ada_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
        "\n",
        "print(\"AdaBoost Accuracy:\", accuracy_ada)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_ada))\n"
      ],
      "metadata": {
        "id": "EzQnL8lfiF7w"
      },
      "id": "EzQnL8lfiF7w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###VISUALIZATION ADABOOST"
      ],
      "metadata": {
        "id": "qIRbDPNeiI87"
      },
      "id": "qIRbDPNeiI87"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test,\n",
        "    y_pred_ada,\n",
        "    cmap='Blues',\n",
        "    xticks_rotation=45\n",
        ")\n",
        "\n",
        "plt.title(\"Confusion Matrix - AdaBoost Classifier\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XOjxpjE_iK-A"
      },
      "id": "XOjxpjE_iK-A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GRADIENT BOOSTING CLASSIFIER"
      ],
      "metadata": {
        "id": "B8yiHbfsh6ZB"
      },
      "id": "B8yiHbfsh6ZB"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Gradient Boosting Classifier Pipeline\n",
        "gb_model = Pipeline(steps=[\n",
        "    ('pre', preprocessor),\n",
        "    ('model', GradientBoostingClassifier(\n",
        "        n_estimators=200,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=3,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
        "\n",
        "print(\"Gradient Boosting Accuracy:\", accuracy_gb)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_gb))\n"
      ],
      "metadata": {
        "id": "tWSaz6kRihgH"
      },
      "id": "tWSaz6kRihgH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###VISUALIZATION"
      ],
      "metadata": {
        "id": "NuT5nxncidcc"
      },
      "id": "NuT5nxncidcc"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test,\n",
        "    y_pred_gb,\n",
        "    cmap='Blues',\n",
        "    xticks_rotation=45\n",
        ")\n",
        "\n",
        "plt.title(\"Confusion Matrix - Gradient Boosting Classifier\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ROYoP9tFimKj"
      },
      "id": "ROYoP9tFimKj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EXTRA TREES"
      ],
      "metadata": {
        "id": "nFK-QOPlid1a"
      },
      "id": "nFK-QOPlid1a"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Extra Trees Classifier Pipeline\n",
        "et_model = Pipeline(steps=[\n",
        "    ('pre', preprocessor),\n",
        "    ('model', ExtraTreesClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=None,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train\n",
        "et_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_et = et_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy_et = accuracy_score(y_test, y_pred_et)\n",
        "\n",
        "print(\"Extra Trees Accuracy:\", accuracy_et)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_et))\n"
      ],
      "metadata": {
        "id": "jgETxlwti4Lp"
      },
      "id": "jgETxlwti4Lp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###VISUALIZATION"
      ],
      "metadata": {
        "id": "qKaNJ3dvjDhc"
      },
      "id": "qKaNJ3dvjDhc"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test,\n",
        "    y_pred_et,\n",
        "    cmap='Blues',\n",
        "    xticks_rotation=45\n",
        ")\n",
        "\n",
        "plt.title(\"Confusion Matrix - Extra Trees Classifier\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3096hcLCjDRn"
      },
      "id": "3096hcLCjDRn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVC"
      ],
      "metadata": {
        "id": "mmNUQtkoxCa6"
      },
      "id": "mmNUQtkoxCa6"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# SVC Pipeline\n",
        "svr_model = Pipeline(steps=[\n",
        "    ('pre', preprocessor),\n",
        "    ('model', SVC(kernel='rbf'))\n",
        "])\n",
        "\n",
        "# Train\n",
        "svr_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_svr = svr_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy_svr = accuracy_score(y_test, y_pred_svr)\n",
        "\n",
        "print(\"SVC Accuracy:\", accuracy_svr)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_svr))\n"
      ],
      "metadata": {
        "id": "H9jRMlknxFOY"
      },
      "id": "H9jRMlknxFOY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Visualization(Actual Vs Predicted SVC)"
      ],
      "metadata": {
        "id": "64MGxJXNx-7C"
      },
      "id": "64MGxJXNx-7C"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test,\n",
        "    y_pred_svr,\n",
        "    cmap='Blues',\n",
        "    xticks_rotation=45\n",
        ")\n",
        "\n",
        "plt.title(\"Confusion Matrix - SVC\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "M3kYUMGmyF6e"
      },
      "id": "M3kYUMGmyF6e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DECISION TREE CLASSIFIER"
      ],
      "metadata": {
        "id": "-Q9C90VbyRpk"
      },
      "id": "-Q9C90VbyRpk"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Decision Tree Classifier Pipeline\n",
        "dt_model = Pipeline(steps=[\n",
        "    ('pre', preprocessor),\n",
        "    ('model', DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Train\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "\n",
        "print(\"Decision Tree Accuracy:\", accuracy_dt)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_dt))\n"
      ],
      "metadata": {
        "id": "VFJyftfAyUsv"
      },
      "id": "VFJyftfAyUsv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Visualization(Actual Vs Predicted Decision Tree Classifier)"
      ],
      "metadata": {
        "id": "YXK59xKKByu4"
      },
      "id": "YXK59xKKByu4"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test,\n",
        "    y_pred_dt,\n",
        "    cmap='Blues',\n",
        "    xticks_rotation=45\n",
        ")\n",
        "\n",
        "plt.title(\"Confusion Matrix - Decision Tree Classifier\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LqQuA1Sayj8H"
      },
      "id": "LqQuA1Sayj8H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RANDOMFOREST CLASSIFIER"
      ],
      "metadata": {
        "id": "uX-QXtkOEBEV"
      },
      "id": "uX-QXtkOEBEV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e44ae96",
      "metadata": {
        "id": "7e44ae96"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Random Forest Classifier pipeline\n",
        "rf_model = Pipeline([\n",
        "    (\"pre\", preprocessor),\n",
        "    (\"model\", RandomForestClassifier(\n",
        "        n_estimators=200,\n",
        "        max_depth=20,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Fit model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"Random Forest Accuracy: {accuracy_rf:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization(Actual vs Predicted RandomForestCla)"
      ],
      "metadata": {
        "id": "I8PajQ_CCpGj"
      },
      "id": "I8PajQ_CCpGj"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test,\n",
        "    y_pred_rf,\n",
        "    cmap='Blues',\n",
        "    xticks_rotation=45\n",
        ")\n",
        "\n",
        "plt.title(\"Confusion Matrix - Random Forest Classifier\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9Vp_bxNiCzU5"
      },
      "id": "9Vp_bxNiCzU5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Top Feature Importances (RandomForest)"
      ],
      "metadata": {
        "id": "RWf5XxJ6EkpU"
      },
      "id": "RWf5XxJ6EkpU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the trained RandomForest model\n",
        "rf = rf_model.named_steps[\"model\"]\n",
        "\n",
        "# Get encoded categorical feature names\n",
        "ohe = rf_model.named_steps[\"pre\"].named_transformers_[\"cat\"]\n",
        "cat_feature_names = ohe.get_feature_names_out(categorical_features).tolist()\n",
        "\n",
        "# Combine with numeric feature names\n",
        "all_feature_names = numeric_features + cat_feature_names\n",
        "\n",
        "# Create importance dataframe\n",
        "importances = pd.DataFrame({\n",
        "    \"feature\": all_feature_names,\n",
        "    \"importance\": rf.feature_importances_\n",
        "})\n",
        "\n",
        "# Sort and plot top 20\n",
        "top_features = importances.sort_values(\"importance\", ascending=False).head(20)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.barh(top_features[\"feature\"], top_features[\"importance\"], color=\"purple\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.title(\"Top 20 Important Features (RandomForest)\")\n",
        "plt.xlabel(\"Importance Score\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2s4I5ceBElh2"
      },
      "id": "2s4I5ceBElh2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XG BOOST CLASSIFIER"
      ],
      "metadata": {
        "id": "tFaajnrjDS8F"
      },
      "id": "tFaajnrjDS8F"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8948ee81",
      "metadata": {
        "id": "8948ee81"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# XGBoost Classifier Pipeline\n",
        "xgb_model = Pipeline([\n",
        "    (\"pre\", preprocessor),\n",
        "    (\"model\", XGBClassifier(\n",
        "        objective='multi:softprob',\n",
        "        n_estimators=200,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        eval_metric='mlogloss'\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "\n",
        "print(f\"XGBoost Accuracy: {accuracy_xgb:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization(Actual Vs Predicted XGBoostCla)"
      ],
      "metadata": {
        "id": "0E1tE_p4DC7l"
      },
      "id": "0E1tE_p4DC7l"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test,\n",
        "    y_pred_xgb,\n",
        "    cmap='Blues',\n",
        "    xticks_rotation=45\n",
        ")\n",
        "\n",
        "plt.title(\"Confusion Matrix - XGBoost Classifier\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fLE23yRjDM4C"
      },
      "id": "fLE23yRjDM4C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Top Feature Importances (SVC)"
      ],
      "metadata": {
        "id": "Gnbo1P6eENeC"
      },
      "id": "Gnbo1P6eENeC"
    },
    {
      "cell_type": "code",
      "source": [
        "    # Extract the trained XGBoost model\n",
        "    xgb = xgb_model.named_steps[\"model\"]\n",
        "\n",
        "    # Get feature names (numeric + encoded categorical)\n",
        "    ohe = xgb_model.named_steps[\"pre\"].named_transformers_[\"cat\"]\n",
        "    cat_feature_names = ohe.get_feature_names_out(categorical_features).tolist()\n",
        "\n",
        "    all_feature_names = numeric_features + cat_feature_names\n",
        "\n",
        "    # Get importance scores\n",
        "    importances = pd.DataFrame({\n",
        "        \"feature\": all_feature_names,\n",
        "        \"importance\": xgb.feature_importances_\n",
        "    })\n",
        "\n",
        "    # Sort top 20\n",
        "    top_features = importances.sort_values(\"importance\", ascending=False).head(20)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.barh(top_features[\"feature\"], top_features[\"importance\"], color=\"green\")\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.title(\"Top 20 Important Features (XGBoost)\")\n",
        "    plt.xlabel(\"Importance Score\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "JzXxS3NREOGq"
      },
      "id": "JzXxS3NREOGq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##XGBOOST HYPERTUNING CLASSIFIER"
      ],
      "metadata": {
        "id": "CR6s92I8hyHd"
      },
      "id": "CR6s92I8hyHd"
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "# XGBoost base model\n",
        "xgb_clf = XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Hyperparameter search space\n",
        "param_dist = {\n",
        "    \"model__n_estimators\": [200, 300, 400],\n",
        "    \"model__max_depth\": [3, 5, 7, 9],\n",
        "    \"model__learning_rate\": [0.01, 0.05, 0.1],\n",
        "    \"model__subsample\": [0.7, 0.8, 0.9, 1.0],\n",
        "    \"model__colsample_bytree\": [0.7, 0.8, 0.9, 1.0]\n",
        "}\n",
        "# Pipeline\n",
        "xgb_pipeline = Pipeline(steps=[\n",
        "    (\"pre\", preprocessor),\n",
        "    (\"model\", xgb_clf)\n",
        "])\n",
        "# Randomized Search\n",
        "xgb_search = RandomizedSearchCV(\n",
        "    estimator=xgb_pipeline,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,               # keep it reasonable\n",
        "    scoring='f1_weighted',   # better than accuracy\n",
        "    cv=3,\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "# Train with hyperparameter tuning\n",
        "xgb_search.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "08nIv6y6h2d5"
      },
      "id": "08nIv6y6h2d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Parameters Found:\")\n",
        "print(xgb_search.best_params_)"
      ],
      "metadata": {
        "id": "fNXAzgJniBwP"
      },
      "id": "fNXAzgJniBwP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict with best model\n",
        "y_pred_xgb_tuned = xgb_search.predict(X_test)\n",
        "\n",
        "# Metrics\n",
        "accuracy_xgb_tuned = accuracy_score(y_test, y_pred_xgb_tuned)\n",
        "f1_xgb_tuned = f1_score(y_test, y_pred_xgb_tuned, average='weighted')\n",
        "\n",
        "print(\"Tuned XGBoost Accuracy:\", accuracy_xgb_tuned)\n",
        "print(\"Tuned XGBoost F1-score:\", f1_xgb_tuned)"
      ],
      "metadata": {
        "id": "RPTvuhhQiEWd"
      },
      "id": "RPTvuhhQiEWd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before Tuning Accuracy:\", accuracy_xgb)\n",
        "print(\"After Tuning Accuracy :\", accuracy_xgb_tuned)\n",
        "\n",
        "print(\"Before Tuning F1:\", f1_xgb)\n",
        "print(\"After Tuning F1 :\", f1_xgb_tuned)\n"
      ],
      "metadata": {
        "id": "1abfjS5wiHz0"
      },
      "id": "1abfjS5wiHz0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###VISUALIZATION"
      ],
      "metadata": {
        "id": "LT5oIgIIkJWb"
      },
      "id": "LT5oIgIIkJWb"
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost Performance Comparison\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    \"Version\": [\"Before Tuning\", \"After Tuning\"],\n",
        "    \"Accuracy\": [accuracy_xgb, accuracy_xgb_tuned],\n",
        "    \"F1-score\": [f1_xgb, f1_xgb_tuned]\n",
        "})\n",
        "\n",
        "display(comparison)\n"
      ],
      "metadata": {
        "id": "NyYGoQpqkJFP"
      },
      "id": "NyYGoQpqkJFP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "\n",
        "plt.bar(\n",
        "    comparison[\"Version\"],\n",
        "    comparison[\"Accuracy\"],\n",
        "    color=[\"steelblue\", \"seagreen\"]\n",
        ")\n",
        "\n",
        "plt.title(\"XGBoost Accuracy: Before vs After Hyperparameter Tuning\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-vMn3DLBkPHu"
      },
      "id": "-vMn3DLBkPHu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "\n",
        "plt.bar(\n",
        "    comparison[\"Version\"],\n",
        "    comparison[\"F1-score\"],\n",
        "    color=[\"darkorange\", \"green\"]\n",
        ")\n",
        "\n",
        "plt.title(\"XGBoost F1-score: Before vs After Hyperparameter Tuning\")\n",
        "plt.ylabel(\"F1-score\")\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3m7TAMMrkVNV"
      },
      "id": "3m7TAMMrkVNV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##XGBOOST AFTER MERGE"
      ],
      "metadata": {
        "id": "jRejoTbJl7UF"
      },
      "id": "jRejoTbJl7UF"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "import joblib\n",
        "import numpy as np # Ensure numpy is imported\n",
        "\n",
        "# Create a 'mag_class' column by rounding the 'magnitude' for classification\n",
        "# This part is retained from previous steps to maintain context, but is not the target for the 3-class problem\n",
        "df_model['mag_class'] = df_model['magnitude'].round().astype(int)\n",
        "\n",
        "# Remap 'mag_class' to be 0-indexed for XGBoost\n",
        "unique_classes_mag = sorted(df_model['mag_class'].unique())\n",
        "class_mapping_mag = {old_val: new_val for new_val, old_val in enumerate(unique_classes_mag)}\n",
        "df_model['mag_class'] = df_model['mag_class'].map(class_mapping_mag)\n",
        "\n",
        "# Create a new merged severity class with adjusted thresholds for multi-class classification\n",
        "def merge_severity(mag):\n",
        "    if mag < 7.0:\n",
        "        return \"Moderate\"\n",
        "    elif mag < 8.0:\n",
        "        return \"Strong\"\n",
        "    else:\n",
        "        return \"Major\"\n",
        "\n",
        "df_model[\"severity_3class\"] = df_model[\"magnitude\"].apply(merge_severity)\n",
        "\n",
        "# Check distribution\n",
        "print(\"Severity 3-class distribution:\\n\", df_model[\"severity_3class\"].value_counts())\n",
        "\n",
        "# Encode string labels to numerical labels for XGBoost\n",
        "le = LabelEncoder()\n",
        "df_model[\"severity_3class_encoded\"] = le.fit_transform(df_model[\"severity_3class\"])\n",
        "print(\"Encoded severity classes:\", le.classes_)\n",
        "print(\"Mapping: \", list(zip(le.classes_, le.transform(le.classes_))))\n",
        "\n",
        "# Train-test split for the 3-class classification problem\n",
        "# X should exclude 'magnitude', original 'severity_3class' string, and 'severity_3class_encoded' (if it's the target)\n",
        "X = df_model.drop(columns=[\"magnitude\", \"severity_3class\", \"severity_3class_encoded\"])\n",
        "y = df_model[\"severity_3class_encoded\"] # Use the encoded numerical labels\n",
        "\n",
        "# Re-add stratify=y since there are now multiple classes\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"\\nTrain/Test shapes:\", X_train.shape, X_test.shape)\n",
        "print(\"y_train unique values:\", y_train.unique())\n",
        "print(\"y_test unique values:\", y_test.unique())\n",
        "\n",
        "# Identify numeric and categorical features from the new X\n",
        "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(\"Numeric features for preprocessor:\", numeric_features)\n",
        "print(\"Categorical features for preprocessor:\", categorical_features)\n",
        "\n",
        "# Transformers\n",
        "numeric_transformer = StandardScaler()\n",
        "categorical_transformer = OneHotEncoder(\n",
        "    handle_unknown='ignore',\n",
        "    sparse_output=False\n",
        ")\n",
        "\n",
        "# Build preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"cat\", categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "02YYLe-tmRGn"
      },
      "id": "02YYLe-tmRGn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "xgb_3class = Pipeline(steps=[\n",
        "    (\"pre\", preprocessor),\n",
        "    (\"model\", XGBClassifier(\n",
        "        objective=\"multi:softprob\",\n",
        "        eval_metric=\"mlogloss\",\n",
        "        random_state=42,\n",
        "        n_estimators=300,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train\n",
        "xgb_3class.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_3class = xgb_3class.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy_3class = accuracy_score(y_test, y_pred_3class)\n",
        "f1_3class = f1_score(y_test, y_pred_3class, average=\"weighted\")\n",
        "\n",
        "print(\"3-Class XGBoost Accuracy:\", accuracy_3class)\n",
        "print(\"3-Class XGBoost F1-score:\", f1_3class)\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred_3class))"
      ],
      "metadata": {
        "id": "GDpnA-dal_sC"
      },
      "id": "GDpnA-dal_sC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###VISULAIZATION"
      ],
      "metadata": {
        "id": "hOpfXUH7mDIS"
      },
      "id": "hOpfXUH7mDIS"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test,\n",
        "    y_pred_3class,\n",
        "    cmap=\"Blues\",\n",
        "    xticks_rotation=45\n",
        ")\n",
        "\n",
        "plt.title(\"Confusion Matrix – 3-Class Earthquake Severity\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Vl02DZJDmCjp"
      },
      "id": "Vl02DZJDmCjp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RESULTS"
      ],
      "metadata": {
        "id": "FG3CotMLEuA4"
      },
      "id": "FG3CotMLEuA4"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_lr  = f1_score(y_test, y_pred_lr,  average='weighted')\n",
        "f1_svr = f1_score(y_test, y_pred_svr, average='weighted')\n",
        "f1_dt  = f1_score(y_test, y_pred_dt,  average='weighted')\n",
        "f1_rf  = f1_score(y_test, y_pred_rf,  average='weighted')\n",
        "f1_xgb = f1_score(y_test, y_pred_xgb, average='weighted')\n",
        "f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
        "f1_nb  = f1_score(y_test, y_pred_nb,  average='weighted')\n",
        "\n",
        "f1_ada = f1_score(y_test, y_pred_ada, average='weighted')\n",
        "f1_gb  = f1_score(y_test, y_pred_gb,  average='weighted')\n",
        "f1_et  = f1_score(y_test, y_pred_et,  average='weighted')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a5FBcGkueRNm"
      },
      "id": "a5FBcGkueRNm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c0f2b4e",
      "metadata": {
        "id": "8c0f2b4e"
      },
      "outputs": [],
      "source": [
        "# Final Classification Results Summary\n",
        "\n",
        "results = []\n",
        "\n",
        "results.append({\"Model\": \"Logistic Regression\", \"Accuracy\": accuracy_lr, \"F1-score\": f1_lr})\n",
        "results.append({\"Model\": \"SVC\",                \"Accuracy\": accuracy_svr, \"F1-score\": f1_svr})\n",
        "results.append({\"Model\": \"Decision Tree\",      \"Accuracy\": accuracy_dt, \"F1-score\": f1_dt})\n",
        "results.append({\"Model\": \"Random Forest\",      \"Accuracy\": accuracy_rf, \"F1-score\": f1_rf})\n",
        "results.append({\"Model\": \"XGBoost\",            \"Accuracy\": accuracy_xgb, \"F1-score\": f1_xgb})\n",
        "results.append({\"Model\": \"KNN\",                \"Accuracy\": accuracy_knn, \"F1-score\": f1_knn})\n",
        "results.append({\"Model\": \"Naive Bayes\",        \"Accuracy\": accuracy_nb, \"F1-score\": f1_nb})\n",
        "results.append({\"Model\": \"AdaBoost\",           \"Accuracy\": accuracy_ada, \"F1-score\": f1_ada})\n",
        "results.append({\"Model\": \"Gradient Boosting\",  \"Accuracy\": accuracy_gb, \"F1-score\": f1_gb})\n",
        "results.append({\"Model\": \"Extra Trees\",        \"Accuracy\": accuracy_et, \"F1-score\": f1_et})\n",
        "\n",
        "res_df = pd.DataFrame(results)\n",
        "display(res_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count misclassifications per class\n",
        "errors = y_test != y_pred_rf\n",
        "error_df = pd.DataFrame({\n",
        "    \"Actual Class\": y_test,\n",
        "    \"Predicted Class\": y_pred_rf,\n",
        "    \"Error\": errors\n",
        "})\n",
        "\n",
        "error_counts = error_df[error_df[\"Error\"]].groupby(\"Actual Class\").size()\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "error_counts.plot(kind='bar')\n",
        "plt.title(\"Misclassification Count per Class (Random Forest)\")\n",
        "plt.xlabel(\"Actual Class\")\n",
        "plt.ylabel(\"Number of Errors\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Zh55W4LTGgDa"
      },
      "id": "Zh55W4LTGgDa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors = y_test != y_pred_xgb\n",
        "\n",
        "error_df = pd.DataFrame({\n",
        "    \"Actual Class\": y_test,\n",
        "    \"Predicted Class\": y_pred_xgb,\n",
        "    \"Error\": errors\n",
        "})\n",
        "\n",
        "error_counts = error_df[error_df[\"Error\"]].groupby(\"Actual Class\").size()\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "error_counts.plot(kind='bar')\n",
        "plt.title(\"Misclassification Count per Class (XGBoost)\")\n",
        "plt.xlabel(\"Actual Class\")\n",
        "plt.ylabel(\"Number of Errors\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0Eih87PNGlod"
      },
      "id": "0Eih87PNGlod",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(11,5))\n",
        "\n",
        "plt.bar(res_df[\"Model\"], res_df[\"Accuracy\"], color=\"steelblue\")\n",
        "\n",
        "plt.title(\"Accuracy Comparison of Classification Models\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EOfzHpUYgZ9q"
      },
      "id": "EOfzHpUYgZ9q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(11,5))\n",
        "\n",
        "plt.bar(res_df[\"Model\"], res_df[\"F1-score\"], color=\"darkorange\")\n",
        "\n",
        "plt.title(\"F1-score Comparison of Classification Models\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"F1-score\")\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VAt4CxdheXL6"
      },
      "id": "VAt4CxdheXL6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b974612a",
      "metadata": {
        "id": "b974612a"
      },
      "outputs": [],
      "source": [
        "df_model.to_csv(\"earthquake_cleaned.csv\", index=True)\n",
        "print(\"Cleaned dataset saved as earthquake_cleaned.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "s7VJtQgzFrYV",
        "2re0OzihIZlH",
        "PjVVhUo4IfHw",
        "YqPW1Nb0Iuph",
        "SIsGZlHgKuTU",
        "uX-QXtkOEBEV",
        "tFaajnrjDS8F"
      ],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}